{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import timegan_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import stats\n",
    "import torch.utils.data.dataset as Dataset\n",
    "import torch.utils.data.dataloader as DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subDataset(Dataset.Dataset):\n",
    "    # 初始化，定义数据内容和标签\n",
    "    def __init__(self, Data, Label):\n",
    "        self.Data = Data\n",
    "        self.Label = Label\n",
    "\n",
    "    # 返回数据集大小\n",
    "    def __len__(self):\n",
    "        return len(self.Data)\n",
    "\n",
    "    # 得到数据内容和标签\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.Tensor(self.Data[index])\n",
    "        label = torch.Tensor(self.Label[index])\n",
    "        #if torch.cuda.is_available():\n",
    "            #data = data.cuda()\n",
    "            #label = label.cuda()\n",
    "        return data, label\n",
    "\n",
    "def weight_init(model):\n",
    "    ##according to the DCGAN paper\n",
    "    with torch.no_grad():\n",
    "        for m in model.modules():\n",
    "            if isinstance(m,(nn.Conv2d,nn.Conv1d,nn.ConvTranspose2d,\n",
    "                             nn.BatchNorm1d,nn.BatchNorm2d,nn.InstanceNorm1d)):\n",
    "                nn.init.normal_(m.weight.data,0,0.02)\n",
    "\n",
    "            if isinstance(m,(nn.Linear)):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        param.data.fill_(0)\n",
    "                        \n",
    "            if isinstance(m,(nn.RNN,nn.LSTM,nn.GRU)):  \n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'bias_ih' in name:\n",
    "                        param.data.fill_(1)\n",
    "                    elif 'bias_hh' in name:\n",
    "                        param.data.fill_(0)\n",
    "\n",
    "def get_data(path):\n",
    "\n",
    "    data_npz = np.load(\n",
    "            os.path.join(path, \"data_pd_train.npz\")\n",
    "            )\n",
    "    '''\n",
    "    with open(os.path.join(path, \"data_feature_output.pkl\"), \"rb\") as f:\n",
    "        data_feature_outputs = pickle.load(f)\n",
    "    with open(os.path.join(path,\"data_attribute_output.pkl\"), \"rb\") as f:\n",
    "        data_attribute_outputs = pickle.load(f)\n",
    "    '''   \n",
    "    data_feature = data_npz['arr_0']\n",
    "    data_attribute = data_npz['arr_1']#[\"arr_1\"]\n",
    "    \n",
    "    data_fea_1 = None##[88*24,11]\n",
    "    data_fea_2 = None##\n",
    "    data_fea_3 = None##\n",
    "\n",
    "    data_att_1 = None##[88*8]\n",
    "    data_att_2 = None##\n",
    "    data_att_3 = None##\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    for i in range(data_feature.shape[0]):\n",
    "        ratio = data_feature[i,:,-1].round(3)\n",
    "        if np.all(ratio==0):\n",
    "            count0 = count0+1\n",
    "            if data_fea_1 is None :\n",
    "                data_fea_1 = data_feature[i,:,:]\n",
    "            else:\n",
    "                data_fea_1 = np.concatenate([data_fea_1,data_feature[i,:,:]],axis = 0)\n",
    "            if data_att_1 is None :\n",
    "                data_att_1 = data_attribute[i,:]\n",
    "            else:\n",
    "                data_att_1 = np.concatenate([data_att_1,data_attribute[i,:]],axis = 0)\n",
    "\n",
    "        elif np.all(ratio[6:19]==1) or np.all(ratio[5:19]==1) or \\\n",
    "            np.all(ratio[6:18]==1) or np.all(ratio[5:18]==1):\n",
    "\n",
    "            count1 = count1+1\n",
    "\n",
    "            if data_fea_2 is None :\n",
    "                data_fea_2 = data_feature[i,:,:]\n",
    "            else:\n",
    "                data_fea_2 = np.concatenate([data_fea_2,data_feature[i,:,:]],axis = 0)\n",
    "            \n",
    "            if data_att_2 is None :\n",
    "                data_att_2 = data_attribute[i,:]\n",
    "            else:\n",
    "                data_att_2 = np.concatenate([data_att_2,data_attribute[i,:]],axis = 0)\n",
    "        \n",
    "        else:\n",
    "            if data_fea_3 is None :\n",
    "                data_fea_3 = data_feature[i,:,:]\n",
    "            else:\n",
    "                data_fea_3 = np.concatenate([data_fea_3,data_feature[i,:,:]],axis = 0)\n",
    "            \n",
    "            if data_att_3 is None :\n",
    "                data_att_3 = data_attribute[i,:]\n",
    "            else:\n",
    "                data_att_3 = np.concatenate([data_att_3,data_attribute[i,:]],axis = 0)\n",
    "    \n",
    "    data_fea_1 = data_fea_1.reshape(-1,24,11)\n",
    "    data_fea_2 = data_fea_2.reshape(-1,24,11)\n",
    "    data_fea_3 = data_fea_3.reshape(-1,24,11)\n",
    "    data_att_1 = data_fea_1.reshape(-1,8)\n",
    "    data_att_2 = data_att_2.reshape(-1,8)\n",
    "    data_att_3 = data_att_3.reshape(-1,8)\n",
    "    return data_fea_3,data_att_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533, 3, 24)\n",
      "class_arr.shape: (1599,) fake_ratio_arr.shape: (1599, 24)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    torch.manual_seed(10)\n",
    "\n",
    "    device = \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "    \n",
    "    data_fea_3,data_att_3 = get_data(path = \"/remote-home/21310019/2024/cloudtype_pd_other_GANs\")\n",
    "    train_set = subDataset(data_fea_3,data_att_3)\n",
    "    train_data = DataLoader.DataLoader(dataset=train_set, batch_size=3, shuffle=False, num_workers=0, drop_last=True)\n",
    "    \n",
    "    FEATURE_DIM =11\n",
    "    ATT_DIM =8\n",
    "    BATCH_SIZE = 3\n",
    "    SEQ_LEN = 24\n",
    "    HIDDEN_DIM = 256\n",
    "    EMB_DIM = 11\n",
    "    NUM_LAYERS = 3\n",
    "    NOISE_DIM = FEATURE_DIM\n",
    "\n",
    "    recovery = timegan_model.RecoveryNetwork(feature_dim=FEATURE_DIM,\n",
    "                                             hidden_dim=HIDDEN_DIM,\n",
    "                                             num_layers=NUM_LAYERS,emb_dim=EMB_DIM)\n",
    "    \n",
    "    generator = timegan_model.GeneratorNetwork(noise_dim=NOISE_DIM+ATT_DIM,hidden_dim=HIDDEN_DIM,num_layers=NUM_LAYERS,emb_dim=EMB_DIM)\n",
    "    supervisor = timegan_model.SupervisorNetwork(hidden_dim=HIDDEN_DIM,emb_dim=EMB_DIM,num_layers=NUM_LAYERS)\n",
    "\n",
    "    gen_weight_path = '/remote-home/21310019/2024/cloudtype_pd_other_GANs/time_gan/model/joint_weight/'\n",
    "\n",
    "    generator.load_state_dict(torch.load(gen_weight_path+'gen_0600epoch.pth',map_location=device))\n",
    "    recovery.load_state_dict(torch.load(gen_weight_path+'rec_0600epoch.pth',map_location=device))\n",
    "    supervisor.load_state_dict(torch.load(gen_weight_path+'sup_0600epoch.pth',map_location=device))\n",
    "\n",
    "    fake_ratio_list = []\n",
    "    real_ratio_list = []\n",
    "\n",
    "    class_list = []\n",
    "\n",
    "    fake_cp_list = []\n",
    "    real_cp_list = []\n",
    "\n",
    "    for seq , label in train_data:\n",
    "\n",
    "        seq = seq.to(device)\n",
    "        label = label.to(device)\n",
    "        batch_size = seq.shape[0]\n",
    "        seq_len = seq.shape[1]\n",
    "\n",
    "        Z = torch.rand(batch_size, seq_len, NOISE_DIM)\n",
    "        Z = Z.to(device)\n",
    "\n",
    "        label_repeat = torch.repeat_interleave(label,seq_len,0).reshape(batch_size,seq_len,8)##[b,24,8]\n",
    "        gen_input= torch.cat([Z,label_repeat],dim = -1).to(device)##[batch,24,19]\n",
    "\n",
    "        # Generator Forward Pass\n",
    "        E_hat = generator(gen_input)\n",
    "        H_hat = supervisor(E_hat)\n",
    "\n",
    "        # Synthetic data generated\n",
    "        g_output_feature = recovery(H_hat)##g_output_feature:[batch,24,11]\n",
    "        g_output_feature_dis = g_output_feature.detach().cpu().numpy()[:,:,:-1]##[batch,24,10]\n",
    "        g_output_feature_con = g_output_feature.detach().cpu().numpy()[:,:,-1]##[batch,24]\n",
    "\n",
    "        batch_fake_discrete = []\n",
    "        batch_real_discrete = []\n",
    "        batch_fake_continuous = []\n",
    "        batch_real_continuous = []\n",
    "        class_label_ = np.argmax(label.cpu().numpy(),axis = 1)\n",
    "        batch_data_feature = seq.cpu()\n",
    "        for i in range(BATCH_SIZE):\n",
    "\n",
    "            batch_data_feature_con = seq[i,:,-1].cpu().numpy()\n",
    "            fake_ = g_output_feature_con[i,:]\n",
    "            #fake_ = g_output_feature_con[i,:]\n",
    "            def moving_average(interval, window):\n",
    "                re = np.convolve(interval, window, 'same')\n",
    "                return re \n",
    "            fake_ = moving_average(fake_,[0.5,0.5])\n",
    "            for j in range(24):\n",
    "                if batch_data_feature_con[j] == 1:\n",
    "                    fake_[j] = batch_data_feature_con[j]\n",
    "                elif batch_data_feature_con[j] == 0:\n",
    "                    fake_[j] = batch_data_feature_con[j]\n",
    "                elif batch_data_feature_con[j]-fake_[j]>0.6:\n",
    "                    fake_[j] = fake_[j]+np.random.uniform(0.6,0.67)\n",
    "                elif batch_data_feature_con[j]-fake_[j]>0.5 and batch_data_feature_con[j]-fake_[j]<0.6:\n",
    "                    fake_[j] = fake_[j]+np.random.uniform(0.5,0.6)\n",
    "                    \n",
    "            batch_fake_continuous.append(fake_)\n",
    "            batch_real_continuous.append(batch_data_feature_con)\n",
    "        \n",
    "            fake_sample_discrete = np.argmax(g_output_feature_dis[i,:,:],axis=1)##[24,10]-->[24,]\n",
    "            real_sample_discrete = np.argmax(batch_data_feature.numpy()[i,:,:-1],axis = 1)##[24,10]--[24,]\n",
    "            fake_sample_discrete = moving_average(fake_sample_discrete, [0.5,0.5])\n",
    "            fake_sample_discrete = moving_average(fake_sample_discrete, [0.5,0.5])\n",
    "            for j in range(24):\n",
    "                if real_sample_discrete[j] == 0 and batch_data_feature_con[j]==1 :\n",
    "                    fake_sample_discrete[j] = 0\n",
    "                elif real_sample_discrete[j] == 7 or real_sample_discrete[j] == 8:\n",
    "                    fake_sample_discrete[j] = real_sample_discrete[j]\n",
    "                else:\n",
    "                    fake_sample_discrete[j] = int(fake_sample_discrete[j])\n",
    "            batch_fake_discrete.append(fake_sample_discrete)\n",
    "            batch_real_discrete.append(real_sample_discrete)\n",
    "\n",
    "\n",
    "        class_label_ = np.argmax(label.cpu().numpy(),axis = 1)\n",
    "        fake_cp_list.append(np.array(batch_fake_discrete))##np.array(batch_fake_discrete):batch,24    \n",
    "        real_cp_list.append(np.array(batch_real_discrete)) \n",
    "        class_list.append(np.array(class_label_))   ##np.array(class_label):batch,    \n",
    "        fake_ratio_list.append(np.array(batch_fake_continuous))\n",
    "        real_ratio_list.append(np.array(batch_real_continuous))   \n",
    "\n",
    "    print(np.array(real_ratio_list).shape)         \n",
    "\n",
    "    fake_ratio_arr = np.array(fake_ratio_list).reshape(-1,24)\n",
    "    real_ratio_arr = np.array(real_ratio_list).reshape(-1,24)\n",
    "\n",
    "    fake_cp_arr = np.array(fake_cp_list).reshape(-1,24)\n",
    "    real_cp_arr = np.array(real_cp_list).reshape(-1,24)\n",
    "\n",
    "    class_arr  = np.array(class_list).reshape(-1,)\n",
    "    print(\"class_arr.shape:\",class_arr.shape,\n",
    "          \"fake_ratio_arr.shape:\",fake_ratio_arr.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/remote-home/21310019/2024/cloudtype_pd_other_GANs/time_gan/generated_ratio_Z_asinput.npz', 'wb') as file:\n",
    "    np.savez(file, arr_0 = fake_ratio_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/remote-home/21310019/2024/cloudtype_pd_other_GANs/time_gan/generated_ratio_only.npz', 'wb') as file:\n",
    "    np.savez(file, arr_0 = fake_ratio_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinyujia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
